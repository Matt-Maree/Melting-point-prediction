{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a969ec16-e66c-4941-b2b2-7c034023ca87",
   "metadata": {},
   "source": [
    "# Model Evaluation and Error Analysis\n",
    "\n",
    "This notebook focuses on post-hoc evaluation and diagnostic analysis of the final melting-point prediction models, with particular emphasis on the stacked ensemble.\n",
    "\n",
    "All models have already been trained and final test-set predictions exported prior to this analysis.  \n",
    "The goal here is **not further optimisation**, but to understand:\n",
    "\n",
    "- overall predictive performance on a strictly held-out test set\n",
    "- how errors are distributed across the target range\n",
    "- whether stacking improves robustness relative to individual base models\n",
    "- where the model fails, and whether those failures are systematic or isolated\n",
    "- which molecular features contribute most strongly to predictions\n",
    "\n",
    "The analyses in this notebook are intended to support **model interpretability, reliability assessment, and scientific reasoning**, rather than further exhaustive optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41bf832-cf97-4303-8e53-b6f91a4950a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mp.io import load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47df8c-cd13-4fe6-84ef-571ef8374fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mp.io import get_repo_root\n",
    "\n",
    "ROOT = get_repo_root()\n",
    "fig_dir = ROOT / \"reports\" / \"figures\" / \"Model_evaluation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67afe88-56ff-4e41-90f4-8c4ad27c003e",
   "metadata": {},
   "source": [
    "## Load evaluation artefacts\n",
    "\n",
    "Load saved predictions, ensemble coefficients, and feature importances for post-hoc evaluation of the final models.  \n",
    "All artefacts are reused from earlier steps; no models are trained in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df583cb-1192-418f-8cf1-f61c6bc5aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = pd.read_csv(ROOT/\"data/processed/final_test.csv\", index_col = 0)\n",
    "\n",
    "stacker_weights = load_json(ROOT / \"reports\" / \"stacker_weights.json\")\n",
    "weights = stacker_weights[\"weights\"]\n",
    "\n",
    "df_weights = (\n",
    "    pd.DataFrame.from_dict(weights, orient=\"index\", columns=[\"weight\"])\n",
    "    .rename_axis(\"model\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "preds = pd.read_csv(ROOT / \"reports\" / \"predictions\" / \"final_test_predictions.csv\")\n",
    "\n",
    "cat_fi = pd.read_csv(ROOT / \"reports\" / \"feature_importance\" / \"catboost_feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a477aa-8fb8-415a-8ecc-4d66c586a185",
   "metadata": {},
   "source": [
    "### Parity plot: stacked ensemble\n",
    "\n",
    "This parity plot compares predicted versus true melting points for the stacked ensemble on the final held-out test set.  \n",
    "Points are coloured by absolute error to highlight the distribution of prediction errors across the target range.\n",
    "\n",
    "The ensemble closely follows the ideal \\(y = x\\) relationship across most of the melting-point range, indicating good overall agreement and limited global bias.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f8790-5f3c-4df6-9ec0-3980fc1a86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_err = preds[\"abs_err_stack\"].values\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    c=abs_err,\n",
    "    s=20,\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "plt.plot(lims, lims, linestyle=\"--\", linewidth=1)\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "\n",
    "plt.xlabel(\"True melting point (°C)\")\n",
    "plt.ylabel(\"Predicted melting point (°C)\")\n",
    "plt.title(\"Parity plot: stacked ensemble (final test set)\")\n",
    "\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label(\"Absolute error (°C)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"Parity_plot.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daad524-a8ad-47a3-bc08-3b745365a0bf",
   "metadata": {},
   "source": [
    "### Residual distribution: stacked ensemble vs CatBoost\n",
    "\n",
    "This figure compares the distribution of residuals for the stacked ensemble and the strongest individual base model (CatBoost) on the final test set.  \n",
    "Residuals are centred around zero for both models, indicating limited systematic bias.\n",
    "\n",
    "The stacked ensemble shows a slightly narrower and more concentrated residual distribution, with reduced mass in the tails relative to CatBoost.  \n",
    "This indicates variance reduction through stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf1217-969f-4c2c-abfb-ce0f698d8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_stack = preds[\"resid_stack\"].to_numpy()\n",
    "r_cat = preds[\"resid_cat\"].to_numpy()\n",
    "\n",
    "# Optional: clip extreme tails so the histogram isn't dominated by a few outliers\n",
    "# (keeps the plot interpretable; remove if you prefer raw)\n",
    "clip_pct = 99.5\n",
    "lim = np.percentile(np.abs(np.concatenate([r_stack, r_cat])), clip_pct)\n",
    "r_stack_plot = np.clip(r_stack, -lim, lim)\n",
    "r_cat_plot = np.clip(r_cat, -lim, lim)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "bins = 40\n",
    "plt.hist(r_cat_plot, bins=bins, alpha=0.5, density=True, label=\"CatBoost residuals\")\n",
    "plt.hist(r_stack_plot, bins=bins, alpha=0.5, density=True, label=\"Stacked ensemble residuals\")\n",
    "\n",
    "plt.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "plt.xlabel(\"Residual (predicted − true) (°C)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Residual distribution: stacked ensemble vs CatBoost (final test set)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"Residual_distribution.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b67bfd-767e-4979-b029-1489a78d6adb",
   "metadata": {},
   "source": [
    "### Absolute error distribution across models\n",
    "\n",
    "This violin plot compares the distribution of absolute prediction errors across all base models and the stacked ensemble on the final test set.  \n",
    "The stacked ensemble exhibits a lower median absolute error and a more concentrated error distribution relative to the individual models.\n",
    "\n",
    "In particular, stacking reduces the frequency of large errors, indicating improved robustness rather than isolated gains on a small subset of compounds.  \n",
    "This supports the use of an ensemble approach for melting-point prediction, where individual models capture complementary aspects of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582052c1-28d0-458e-a425-e232167b998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels = [\"CatBoost\", \"XGBoost\", \"kNN\", \"Neural network\", \"Stacked\"]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.violinplot(\n",
    "    data_plot,\n",
    "    showmeans=False,\n",
    "    showmedians=True,\n",
    "    showextrema=False,\n",
    ")\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=range(1, len(model_labels) + 1),\n",
    "    labels=model_labels,\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Absolute error (°C)\")\n",
    "plt.title(\"Absolute error distribution across models (final test set)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"Absolute_error_distribution.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea33508-d318-4870-9e49-ef35dc02b14b",
   "metadata": {},
   "source": [
    "### Residuals vs predicted melting point (stacked ensemble)\n",
    "\n",
    "This plot shows residuals as a function of the predicted melting point for the stacked ensemble, allowing assessment of systematic trends across the prediction range.\n",
    "\n",
    "Residuals are centred around zero throughout, indicating no strong prediction bias as a function of melting point.  \n",
    "A modest increase in spread is observed at higher predicted values, suggesting increased uncertainty in regions of sparser chemical coverage rather than a distinct failure regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b333d-706b-4b37-b2ec-fc3df18210c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preds[\"pred_stack\"].to_numpy()\n",
    "y = preds[\"resid_stack\"].to_numpy()\n",
    "\n",
    "# Optional: clip extreme residuals for readability\n",
    "clip_pct = 99.5\n",
    "lim = np.percentile(np.abs(y), clip_pct)\n",
    "y_plot = np.clip(y, -lim, lim)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(\n",
    "    x,\n",
    "    y_plot,\n",
    "    s=15,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "plt.axhline(0, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "plt.xlabel(\"Predicted melting point (°C)\")\n",
    "plt.ylabel(\"Residual (predicted − true) (°C)\")\n",
    "plt.title(\"Residuals vs predicted melting point (stacked ensemble)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"Residuals_vs_predicted_melting_point.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708da86-0cc6-413a-870f-4dda1efc96f7",
   "metadata": {},
   "source": [
    "### Worst-case absolute errors (stacked ensemble)\n",
    "\n",
    "This table lists the top 15 test-set compounds with the largest absolute prediction errors for the stacked ensemble.  \n",
    "The purpose of this inspection is to assess whether the largest errors reflect systematic failure modes or isolated, compound-specific deviations.\n",
    "\n",
    "The worst errors are distributed across a wide range of true melting points and include both over- and under-predictions.  \n",
    "This suggests that large deviations are not driven by a single target-range effect, but are more likely associated with specific chemical or solid-state features not fully captured by the available descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15a468-11d8-4da0-ab44-b7fcad22b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15 \n",
    "\n",
    "cols = [\"y_true\", \"pred_stack\", \"abs_err_stack\", \"resid_stack\"]\n",
    "worst = (\n",
    "    preds[cols]\n",
    "    .sort_values(\"abs_err_stack\", ascending=False)\n",
    "    .head(N)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Round for readability\n",
    "worst[[\"y_true\", \"pred_stack\", \"abs_err_stack\", \"resid_stack\"]] = worst[\n",
    "    [\"y_true\", \"pred_stack\", \"abs_err_stack\", \"resid_stack\"]\n",
    "].round(2)\n",
    "\n",
    "worst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258fc0bc-add7-48cd-801d-7ce7ad807690",
   "metadata": {},
   "source": [
    "### Stacker weights (model contributions)\n",
    "\n",
    "This plot shows the coefficients learned by the ridge regression meta-learner when combining predictions from the base models.  \n",
    "Coefficients reflect the relative contribution of each model to the stacked ensemble after standardisation of the meta-features.\n",
    "\n",
    "Multiple base models receive non-zero weight, indicating that the ensemble leverages complementary predictive signals rather than relying on a single dominant model.  \n",
    "These coefficients should be interpreted qualitatively, as they depend on feature scaling and regularisation, and do not represent absolute model importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d5d99b-1a1d-43ae-b531-79d4c7d1d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(df_weights[\"model\"], df_weights[\"weight\"])\n",
    "\n",
    "plt.axhline(0, linestyle=\"--\", linewidth=1)\n",
    "plt.ylabel(\"Stacker coefficient\")\n",
    "plt.xlabel(\"Base model\")\n",
    "plt.title(\"Stacker weights (ridge regression meta-learner)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"stacker_weights.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b974a702-e32c-4833-b710-4ad0a94862df",
   "metadata": {},
   "source": [
    "### CatBoost feature importance\n",
    "\n",
    "This figure shows the top 20 features ranked by importance in the CatBoost model, providing insight into which molecular descriptors most strongly influence melting-point predictions.\n",
    "\n",
    "Highly ranked features relate to molecular polarity (e.g. TPSA, hydrogen-bonding descriptors), molecular size and shape (e.g. molecular weight, Bertz complexity), and ring structure.  \n",
    "These factors are consistent with physical intuition for melting point, reflecting the role of intermolecular interactions and solid-state packing rather than specific functional groups alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f570ef3-c218-41e4-b457-07405fae2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20  # top-N features to show\n",
    "\n",
    "fi_top = cat_fi.sort_values(\"importance\", ascending=False).head(N)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.barh(\n",
    "    fi_top[\"feature\"][::-1],       \n",
    "    fi_top[\"importance\"][::-1],\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature importance (CatBoost)\")\n",
    "plt.title(f\"Top {N} CatBoost feature importances\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"CatBoost_feature_importance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc748b63-9c44-43e6-9640-4c134fea32de",
   "metadata": {},
   "source": [
    "## Summary and conclusions\n",
    "\n",
    "This notebook presented a post-hoc evaluation of the final melting-point prediction models, with emphasis on the stacked ensemble.\n",
    "\n",
    "Across multiple complementary diagnostics, the ensemble demonstrates improved robustness relative to individual base models, with reduced error variance and limited systematic bias on the held-out test set.  \n",
    "Inspection of residuals and worst-case errors suggests that remaining failures are sparse and likely driven by compound-specific chemical or solid-state effects rather than target-range extrapolation.\n",
    "\n",
    "Overall, these results support the use of ensemble modelling for melting-point prediction and provide a transparent assessment of model reliability and limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d46c5-b839-4f33-b262-da8c1b3ee652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
